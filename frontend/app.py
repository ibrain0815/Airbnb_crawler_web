"""
Streamlit í”„ë¡ íŠ¸ì—”ë“œ â€” ì—ì–´ë¹„ì•¤ë¹„ í¬ë¡¤ë§ UI.

- ì—ì–´ë¹„ì•¤ë¹„ ì ‘ì† â†’ ìˆ™ë°• í˜ì´ì§€ ì„ íƒ í›„, ì£¼ì†Œì°½ URLì„ ë³µì‚¬í•´ ì•„ë˜ ì…ë ¥ë€ì— ë¶™ì—¬ë„£ê¸°
- í¬ë¡¤ë§ ì‹œì‘ ì‹œ í•´ë‹¹ URLë¡œ ìˆ˜ì§‘, ì§„í–‰ í˜„í™© ì‹¤ì‹œê°„ í‘œì‹œ â†’ ì—‘ì…€ ë‚´ë³´ë‚´ê¸°
"""
import os
import time
from datetime import datetime
from typing import Any

import requests
import streamlit as st


def _get_backend_url() -> str:
    """ë¡œì»¬ì€ .env, Streamlit CloudëŠ” Secretsì—ì„œ BACKEND_URL ì½ê¸°."""
    try:
        if hasattr(st, "secrets") and st.secrets is not None:
            url = st.secrets.get("BACKEND_URL")
            if url:
                return str(url).rstrip("/")
    except Exception:
        pass
    return os.getenv("BACKEND_URL", "http://localhost:8000").rstrip("/")


# ì§€ì—° ê³„ì‚°: import ì‹œ st.secrets ë¯¸ì¤€ë¹„ë¡œ ì˜¤ë¥˜ ë‚˜ëŠ” ê²ƒ ë°©ì§€ (Streamlit Cloud ë“±)
def _backend_url() -> str:
    """ë§¤ë²ˆ ì¡°íšŒ (session_state ë¯¸ì‚¬ìš©ìœ¼ë¡œ Cloud ì´ˆê¸°í™” ì´ìŠˆ íšŒí”¼)."""
    return _get_backend_url()


AIRBNB_URL = "https://www.airbnb.co.kr/"


def check_backend() -> bool:
    """ë°±ì—”ë“œ ì—°ê²° í™•ì¸."""
    try:
        r = requests.get(f"{_backend_url()}/health", timeout=3)
        return r.status_code == 200
    except Exception:
        return False


def start_crawl_sync(search_url: str, max_pages: int) -> list[dict] | None:
    """
    ë™ê¸° í¬ë¡¤ë§ í˜¸ì¶œ.
    - POST /crawl_sync
    - ì„œë²„ëŠ” JobManager ì— ìƒíƒœë¥¼ ì €ì¥í•˜ì§€ ì•Šê³ , ê²°ê³¼ JSON ë§Œ ë°˜í™˜.
    """
    try:
        r = requests.post(
            f"{_backend_url()}/crawl_sync",
            json={"search_url": search_url, "max_pages": max_pages},
            timeout=600,
        )
        r.raise_for_status()
        data = r.json()
        if data.get("status") != "completed":
            st.error(f"í¬ë¡¤ë§ ì‹¤íŒ¨: {data.get('error') or data.get('detail') or 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}")
            return None
        listings = data.get("listings")
        return listings if isinstance(listings, list) else []
    except Exception as e:
        st.error(f"í¬ë¡¤ë§ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None


def get_excel_from_backend(listings: list[dict]) -> bytes | None:
    """
    í”„ë¡ íŠ¸ì— ì €ì¥ëœ listings ë¥¼ ë°±ì—”ë“œë¡œ ë³´ë‚´ ì—‘ì…€ íŒŒì¼ bytes ë¡œ ë³€í™˜.
    - ì„œë²„ëŠ” ìš”ì²­ ë²”ìœ„ ë‚´ì—ì„œë§Œ ì²˜ë¦¬í•˜ê³ , ê²°ê³¼ë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŒ.
    """
    try:
        r = requests.post(
            f"{_backend_url()}/excel-from-listings",
            json={"listings": listings},
            timeout=120,
        )
        r.raise_for_status()
        return r.content
    except Exception as e:
        st.error(f"ì—‘ì…€ ìƒì„± ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None


def main() -> None:
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except Exception:
        pass
    st.set_page_config(page_title="ì—ì–´ë¹„ì•¤ë¹„ ìˆ™ì†Œ í¬ë¡¤ëŸ¬", layout="centered")
    st.title("ì—ì–´ë¹„ì•¤ë¹„ ìˆ™ì†Œ ì •ë³´ í¬ë¡¤ëŸ¬")

    # --------------------------------------------------
    # Step 1: ì—ì–´ë¹„ì•¤ë¹„ ì ‘ì†
    # --------------------------------------------------
    st.subheader("1ë‹¨ê³„: ì—ì–´ë¹„ì•¤ë¹„ ì ‘ì†")
    st.markdown(
        '<a href="' + AIRBNB_URL + '" target="_blank" rel="noopener noreferrer" '
        'style="display:inline-block; background:#FF5A5F; color:white; padding:0.6rem 1.2rem; '
        'text-decoration:none; border-radius:8px; font-weight:bold;">ğŸ”— ì—ì–´ë¹„ì•¤ë¹„ ì ‘ì†</a>',
        unsafe_allow_html=True,
    )
    st.caption("ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì—ì–´ë¹„ì•¤ë¹„ê°€ ìƒˆ íƒ­ì—ì„œ ì—´ë¦½ë‹ˆë‹¤.")

    st.divider()

    # --------------------------------------------------
    # Step 2: ìˆ™ë°•ì§€ í˜ì´ì§€ URL â€” ìˆ˜ë™ ë³µì‚¬Â·ë¶™ì—¬ë„£ê¸°
    # --------------------------------------------------
    st.subheader("2ë‹¨ê³„: ìˆ™ë°•ì§€ í˜ì´ì§€ URL")
    st.info(
        "ì—ì–´ë¹„ì•¤ë¹„ì—ì„œ **ìˆ™ë°• ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€**ë¡œ ì´ë™í•œ ë’¤, **ì£¼ì†Œì°½ì˜ URL**ì„ ë³µì‚¬(Ctrl+C)í•˜ì—¬ ì•„ë˜ ì…ë ¥ë€ì— **ë¶™ì—¬ë„£ê¸°(Ctrl+V)** í•´ ì£¼ì„¸ìš”."
    )

    search_url = st.text_input(
        "ê²€ìƒ‰ ê²°ê³¼ URL (ìˆ™ë°•ì§€ í˜ì´ì§€ ì£¼ì†Œ)",
        value="",
        placeholder="https://www.airbnb.co.kr/s/ì„œìš¸/homes?...",
        help="ì—ì–´ë¹„ì•¤ë¹„ ìˆ™ë°• ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ì˜ ì£¼ì†Œë¥¼ ë³µì‚¬í•´ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.",
        key="search_url",
    )
    max_pages = st.number_input(
        "ìµœëŒ€ í¬ë¡¤ë§ í˜ì´ì§€ ìˆ˜",
        min_value=1,
        max_value=20,
        value=5,
        step=1,
        help="ìˆ˜ì§‘í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (1í˜ì´ì§€ë‹¹ ì—¬ëŸ¬ ê°œ ìˆ™ì†Œ)",
    )

    st.divider()

    # --------------------------------------------------
    # Step 3: í¬ë¡¤ë§ ì‹¤í–‰ (ë™ê¸° í˜¸ì¶œ, ê²°ê³¼ëŠ” í”„ë¡ íŠ¸ ì„¸ì…˜ì—ë§Œ ì €ì¥)
    # --------------------------------------------------
    st.subheader("3ë‹¨ê³„: í¬ë¡¤ë§ ë° ì—‘ì…€ ë‚´ë³´ë‚´ê¸°")

    if "listings" not in st.session_state:
        st.session_state["listings"] = []

    if st.button("í¬ë¡¤ë§ ì‹œì‘", type="primary"):
        url_to_use = (search_url or "").strip()
        if not url_to_use:
            st.warning("2ë‹¨ê³„ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ URLì„ ë³µì‚¬í•´ ë¶™ì—¬ë„£ì–´ ì£¼ì„¸ìš”.")
        else:
            if not check_backend():
                st.error(
                    f"ë°±ì—”ë“œì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({_backend_url()})\n\n"
                    "ë°±ì—”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”:\n"
                    "`cd backend` í›„ `python -m uvicorn main:app --reload`"
                )
            else:
                with st.spinner("í¬ë¡¤ë§ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."):
                    listings = start_crawl_sync(url_to_use, max_pages)
                if listings is not None:
                    st.session_state["listings"] = listings
                    st.session_state["last_crawl_meta"] = {
                        "search_url": url_to_use,
                        "max_pages": max_pages,
                        "total_listings": len(listings),
                        "finished_at": datetime.now().isoformat(timespec="seconds"),
                    }

    listings = st.session_state.get("listings") or []

    if listings:
        meta = st.session_state.get("last_crawl_meta", {})
        st.subheader("ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼ (ë¡œì»¬ ì„¸ì…˜ì— ì €ì¥ë¨)")
        if meta:
            st.caption(
                f"URL: `{meta.get('search_url', '')}` Â· "
                f"í˜ì´ì§€: {meta.get('max_pages', 0)} Â· "
                f"ì´ {meta.get('total_listings', len(listings))}ê±´ Â· "
                f"ì™„ë£Œ ì‹œê°: {meta.get('finished_at', '')}"
            )

        st.dataframe(listings, use_container_width=True)

        st.subheader("ì—‘ì…€ ë‚´ë³´ë‚´ê¸°")
        excel_bytes = get_excel_from_backend(listings)
        if excel_bytes:
            st.download_button(
                label="ì—‘ì…€ íŒŒì¼ ë‚´ë³´ë‚´ê¸°",
                data=excel_bytes,
                file_name=f"airbnb_listings_{int(time.time())}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )


# Streamlit CloudëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ import ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆì–´, __main__ì¼ ë•Œë§Œ ì‹¤í–‰í•˜ë©´ main()ì´ í˜¸ì¶œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ.
# ë”°ë¼ì„œ ì¡°ê±´ ì—†ì´ main() ì‹¤í–‰ (ë¡œì»¬ streamlit run ì‹œì—ë„ ë™ì¼í•˜ê²Œ ì‹¤í–‰ë¨)
try:
    main()
except Exception as e:
    st.error("ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    st.code(str(e), language=None)
    st.exception(e)
