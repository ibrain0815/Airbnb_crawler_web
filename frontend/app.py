"""
Streamlit í”„ë¡ íŠ¸ì—”ë“œ â€” ì—ì–´ë¹„ì•¤ë¹„ í¬ë¡¤ë§ UI.

- ì—ì–´ë¹„ì•¤ë¹„ ì ‘ì† â†’ ìˆ™ë°• í˜ì´ì§€ ì„ íƒ í›„, ì£¼ì†Œì°½ URLì„ ë³µì‚¬í•´ ì•„ë˜ ì…ë ¥ë€ì— ë¶™ì—¬ë„£ê¸°
- í¬ë¡¤ë§ ì‹œì‘ ì‹œ í•´ë‹¹ URLë¡œ ìˆ˜ì§‘, ì§„í–‰ í˜„í™© ì‹¤ì‹œê°„ í‘œì‹œ â†’ ì—‘ì…€ ë‚´ë³´ë‚´ê¸°
"""
import os
import time
from datetime import datetime
from typing import Any

import requests
import streamlit as st


def _get_backend_url() -> str:
    """ë¡œì»¬ì€ .env, Streamlit CloudëŠ” Secretsì—ì„œ BACKEND_URL ì½ê¸°."""
    try:
        if hasattr(st, "secrets") and st.secrets is not None:
            url = st.secrets.get("BACKEND_URL")
            if url:
                return str(url).rstrip("/")
    except Exception:
        pass
    return os.getenv("BACKEND_URL", "http://localhost:8000").rstrip("/")


# ì§€ì—° ê³„ì‚°: import ì‹œ st.secrets ë¯¸ì¤€ë¹„ë¡œ ì˜¤ë¥˜ ë‚˜ëŠ” ê²ƒ ë°©ì§€ (Streamlit Cloud ë“±)
def _backend_url() -> str:
    """ë§¤ë²ˆ ì¡°íšŒ (session_state ë¯¸ì‚¬ìš©ìœ¼ë¡œ Cloud ì´ˆê¸°í™” ì´ìŠˆ íšŒí”¼)."""
    return _get_backend_url()


AIRBNB_URL = "https://www.airbnb.co.kr/"


def check_backend() -> bool:
    """ë°±ì—”ë“œ ì—°ê²° í™•ì¸."""
    try:
        r = requests.get(f"{_backend_url()}/health", timeout=3)
        return r.status_code == 200
    except Exception:
        return False


def start_crawl(search_url: str, max_pages: int) -> str | None:
    """POST /crawl í˜¸ì¶œ í›„ job_id ë°˜í™˜. ì‹¤íŒ¨ ì‹œ None."""
    try:
        r = requests.post(
            f"{_backend_url()}/crawl",
            json={"search_url": search_url, "max_pages": max_pages},
            timeout=10,
        )
        r.raise_for_status()
        return r.json().get("job_id")
    except Exception as e:
        st.error(f"í¬ë¡¤ë§ ì‹œì‘ ì‹¤íŒ¨: {e}")
        return None


def fetch_status(job_id: str) -> dict:
    """í˜„ì¬ ìƒíƒœ 1íšŒ ì¡°íšŒ. ì‹¤íŒ¨ ì‹œ failed ìƒíƒœ ë°˜í™˜."""
    try:
        r = requests.get(f"{_backend_url()}/crawl/{job_id}/status/json", timeout=10)
        if r.status_code == 404:
            return {
                "status": "failed",
                "error_message": "ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë°±ì—”ë“œ ì¬ì‹œì‘ ì‹œ ì´ì „ ì‘ì—…ì€ ì‚¬ë¼ì§‘ë‹ˆë‹¤) í¬ë¡¤ë§ì„ ë‹¤ì‹œ ì‹œì‘í•´ ì£¼ì„¸ìš”.",
                "job_not_found": True,
            }
        r.raise_for_status()
        return r.json()
    except requests.exceptions.RequestException as e:
        return {"status": "failed", "error_message": str(e)}
    except Exception as e:
        return {"status": "failed", "error_message": str(e)}


def get_download_url(job_id: str) -> str:
    return f"{_backend_url()}/crawl/{job_id}/download"


def main() -> None:
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except Exception:
        pass
    st.set_page_config(page_title="ì—ì–´ë¹„ì•¤ë¹„ ìˆ™ì†Œ í¬ë¡¤ëŸ¬", layout="centered")
    st.title("ì—ì–´ë¹„ì•¤ë¹„ ìˆ™ì†Œ ì •ë³´ í¬ë¡¤ëŸ¬")

    # --------------------------------------------------
    # Step 1: ì—ì–´ë¹„ì•¤ë¹„ ì ‘ì†
    # --------------------------------------------------
    st.subheader("1ë‹¨ê³„: ì—ì–´ë¹„ì•¤ë¹„ ì ‘ì†")
    st.markdown(
        '<a href="' + AIRBNB_URL + '" target="_blank" rel="noopener noreferrer" '
        'style="display:inline-block; background:#FF5A5F; color:white; padding:0.6rem 1.2rem; '
        'text-decoration:none; border-radius:8px; font-weight:bold;">ğŸ”— ì—ì–´ë¹„ì•¤ë¹„ ì ‘ì†</a>',
        unsafe_allow_html=True,
    )
    st.caption("ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì—ì–´ë¹„ì•¤ë¹„ê°€ ìƒˆ íƒ­ì—ì„œ ì—´ë¦½ë‹ˆë‹¤.")

    st.divider()

    # --------------------------------------------------
    # Step 2: ìˆ™ë°•ì§€ í˜ì´ì§€ URL â€” ìˆ˜ë™ ë³µì‚¬Â·ë¶™ì—¬ë„£ê¸°
    # --------------------------------------------------
    st.subheader("2ë‹¨ê³„: ìˆ™ë°•ì§€ í˜ì´ì§€ URL")
    st.info(
        "ì—ì–´ë¹„ì•¤ë¹„ì—ì„œ **ìˆ™ë°• ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€**ë¡œ ì´ë™í•œ ë’¤, **ì£¼ì†Œì°½ì˜ URL**ì„ ë³µì‚¬(Ctrl+C)í•˜ì—¬ ì•„ë˜ ì…ë ¥ë€ì— **ë¶™ì—¬ë„£ê¸°(Ctrl+V)** í•´ ì£¼ì„¸ìš”."
    )

    search_url = st.text_input(
        "ê²€ìƒ‰ ê²°ê³¼ URL (ìˆ™ë°•ì§€ í˜ì´ì§€ ì£¼ì†Œ)",
        value="",
        placeholder="https://www.airbnb.co.kr/s/ì„œìš¸/homes?...",
        help="ì—ì–´ë¹„ì•¤ë¹„ ìˆ™ë°• ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ì˜ ì£¼ì†Œë¥¼ ë³µì‚¬í•´ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.",
        key="search_url",
    )
    max_pages = st.number_input(
        "ìµœëŒ€ í¬ë¡¤ë§ í˜ì´ì§€ ìˆ˜",
        min_value=1,
        max_value=20,
        value=5,
        step=1,
        help="ìˆ˜ì§‘í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (1í˜ì´ì§€ë‹¹ ì—¬ëŸ¬ ê°œ ìˆ™ì†Œ)",
    )

    st.divider()

    # --------------------------------------------------
    # Step 3: í¬ë¡¤ë§ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ + ì§„í–‰ë¥  í´ë§)
    # --------------------------------------------------
    st.subheader("3ë‹¨ê³„: í¬ë¡¤ë§ ë° ì—‘ì…€ ë‚´ë³´ë‚´ê¸°")
    if st.button("í¬ë¡¤ë§ ì‹œì‘", type="primary"):
        url_to_use = (search_url or "").strip()
        if not url_to_use:
            st.warning("2ë‹¨ê³„ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ URLì„ ë³µì‚¬í•´ ë¶™ì—¬ë„£ì–´ ì£¼ì„¸ìš”.")
        else:
            if not check_backend():
                st.error(
                    f"ë°±ì—”ë“œì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({_backend_url()})\n\n"
                    "ë°±ì—”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”:\n"
                    "`cd backend` í›„ `python -m uvicorn main:app --reload`"
                )
            else:
                job_id = start_crawl(url_to_use, max_pages)
                if job_id:
                    st.session_state["job_id"] = job_id
                    st.session_state["max_pages"] = max_pages
                    st.session_state["progress_log"] = []

    job_id = st.session_state.get("job_id")
    if not job_id:
        return

    # --------------------------------------------------
    # ì§„í–‰ í˜„í™© (ì‹¤ì‹œê°„)
    # --------------------------------------------------
    if "progress_log" not in st.session_state:
        st.session_state["progress_log"] = []

    st.subheader("ğŸ“Š í¬ë¡¤ë§ ì§„í–‰ í˜„í™©")
    st.caption("ë°±ì—”ë“œì—ì„œ ìƒíƒœë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘â€¦ ì—°ê²°ì´ ì•ˆ ë˜ë©´ ì•„ë˜ì— ì˜¤ë¥˜ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    log_placeholder = st.empty()
    table_placeholder = st.empty()

    last_data: dict[str, Any] = {}
    data = fetch_status(job_id)
    last_data = data
    with st.expander("ë°±ì—”ë“œ ìƒíƒœ ì‘ë‹µ (JSON)", expanded=False):
        st.json(data)
    status = data.get("status", "")
    current = data.get("current_page", 0)
    total = data.get("max_pages", 1) or 1
    total_listings = data.get("total_listings", 0)
    listings = data.get("listings") if isinstance(data.get("listings"), list) else []
    progress_pct = data.get("progress_percent", 0) or (100 * current / total if total else 0)

    # ë¡œê·¸ í•œ ì¤„ ì¶”ê°€
    ts = datetime.now().strftime("%H:%M:%S")
    log_line = f"[{ts}] í˜ì´ì§€ {current}/{total} Â· ìˆ˜ì§‘ {total_listings}ê±´ Â· ìƒíƒœ: {status}"
    if not st.session_state["progress_log"] or st.session_state["progress_log"][-1] != log_line:
        st.session_state["progress_log"].append(log_line)

    # ì§„í–‰ë¥  ë°”
    progress_placeholder.progress(progress_pct / 100.0)

    # ìš”ì•½ ìƒíƒœ
    status_placeholder.markdown(
        f"""
        | í•­ëª© | ê°’ |
        |------|-----|
        | **ìƒíƒœ** | `{status}` |
        | **í˜„ì¬ í˜ì´ì§€** | {current} / {total} |
        | **ìˆ˜ì§‘ ê±´ìˆ˜** | **{total_listings}ê±´** |
        | **ì§„í–‰ë¥ ** | {progress_pct:.1f}% |
        """
    )

    # ì§„í–‰ ë¡œê·¸ (ìµœê·¼ 20ì¤„)
    log_text = "\n".join(st.session_state["progress_log"][-20:])
    log_placeholder.code(log_text or "ëŒ€ê¸° ì¤‘...", language=None)

    if listings:
        table_placeholder.dataframe(listings, use_container_width=True)

    if status == "failed":
        err_msg = data.get("error_message") or "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
        st.error(err_msg)
        if "job_id" in st.session_state:
            del st.session_state["job_id"]
        st.info("ì•„ë˜ì—ì„œ URLì„ ì…ë ¥í•œ ë’¤ **í¬ë¡¤ë§ ì‹œì‘**ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
        if st.button("ì²˜ìŒìœ¼ë¡œ (ì…ë ¥ í™”ë©´ìœ¼ë¡œ ëŒì•„ê°€ê¸°)", type="primary"):
            st.rerun()
        st.stop()
    if status == "completed":
        st.success(f"í¬ë¡¤ë§ ì™„ë£Œ: ì´ {total_listings}ê±´ ìˆ˜ì§‘")
    else:
        auto = st.checkbox("ìë™ ê°±ì‹ (2ì´ˆ)", value=True)
        if st.button("ìƒíƒœ ìƒˆë¡œê³ ì¹¨"):
            st.rerun()
        if auto:
            time.sleep(2)
            st.rerun()

    # ì—‘ì…€ ë‚´ë³´ë‚´ê¸°
    listings_for_download = last_data.get("listings") if isinstance(last_data.get("listings"), list) else []
    if last_data.get("status") == "completed" and listings_for_download:
        st.subheader("ì—‘ì…€ ë‚´ë³´ë‚´ê¸°")
        try:
            resp = requests.get(get_download_url(job_id), timeout=30)
            if resp.status_code == 200:
                st.download_button(
                    label="ì—‘ì…€ íŒŒì¼ ë‚´ë³´ë‚´ê¸°",
                    data=resp.content,
                    file_name=f"airbnb_listings_{int(time.time())}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )
            else:
                st.warning("ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ë‹¤ìš´ë¡œë“œ ìš”ì²­ ì‹¤íŒ¨: {e}")


# Streamlit CloudëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ import ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆì–´, __main__ì¼ ë•Œë§Œ ì‹¤í–‰í•˜ë©´ main()ì´ í˜¸ì¶œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ.
# ë”°ë¼ì„œ ì¡°ê±´ ì—†ì´ main() ì‹¤í–‰ (ë¡œì»¬ streamlit run ì‹œì—ë„ ë™ì¼í•˜ê²Œ ì‹¤í–‰ë¨)
try:
    main()
except Exception as e:
    st.error("ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    st.code(str(e), language=None)
    st.exception(e)
